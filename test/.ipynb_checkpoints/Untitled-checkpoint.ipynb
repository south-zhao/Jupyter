{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6d297249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f60ee",
   "metadata": {},
   "source": [
    "### 附件1的读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "70977c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = pd.read_excel(\"附件1：123家有信贷记录企业的相关数据.xlsx\", sheet_name=\"企业信息\")\n",
    "df1_2 = pd.read_excel(\"附件1：123家有信贷记录企业的相关数据.xlsx\", sheet_name=\"进项发票信息\")\n",
    "df1_3 = pd.read_excel(\"附件1：123家有信贷记录企业的相关数据.xlsx\", sheet_name=\"销项发票信息\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33c45e",
   "metadata": {},
   "source": [
    "### 将对应信息整合到一个表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b7de43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to = list(df1_1[\"企业代号\"])\n",
    "id0 = []\n",
    "id0_degree = []\n",
    "id1 = []\n",
    "id1_degree = []\n",
    "for i in id_to:\n",
    "    # 获取总次数\n",
    "    df1_31 = df1_3[df1_3[\"企业代号\"]==i]\n",
    "    total = df1_31.count()[0]\n",
    "    ok_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]>=0)].count()[0] / total\n",
    "    fu_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]<0)].count()[0] / total\n",
    "    not_num = df1_31[df1_31[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "    money_avg = df1_31[df1_31[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "    not_num1 = df1_31[(df1_31[\"发票状态\"]==\"作废发票\") & (df1_31[\"金额\"]==0)].count()[0] / total \n",
    "    degree = list(df1_1[df1_1[\"企业代号\"]==i][\"信誉评级\"])\n",
    "    if not_num1 > 0.05:\n",
    "        id0.append(i)\n",
    "        id0_degree.extend(degree)\n",
    "    else:\n",
    "        id1.append(i)\n",
    "        id1_degree.extend(degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9d88ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取企业代号\n",
    "def new_data(id0, name):\n",
    "    # 每个企业对应的进项发票各类状态占比\n",
    "    in_ok = []  # 有效占比\n",
    "    in_fu = []  # 负数占比\n",
    "    in_not = []  # 作废占比\n",
    "    in_count = []  # 次数\n",
    "    in_money = []  # 金额/次\n",
    "    for i in id0:\n",
    "        # 获取总次数\n",
    "        df1_21 = df1_2[df1_2[\"企业代号\"]==i]\n",
    "        total = df1_21.count()[0]\n",
    "        ok_num = df1_21[(df1_21[\"发票状态\"]==\"有效发票\") & (df1_21[\"金额\"]>=0)].count()[0] / total\n",
    "        fu_num = df1_21[(df1_21[\"发票状态\"]==\"有效发票\") & (df1_21[\"金额\"]<0)].count()[0] / total\n",
    "        not_num = df1_21[df1_21[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "        money_avg = df1_21[df1_21[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "        in_ok.append(ok_num)\n",
    "        in_fu.append(fu_num)\n",
    "        in_not.append(not_num)\n",
    "        in_count.append(total)\n",
    "        in_money.append(money_avg)\n",
    "\n",
    "    # 每个企业对应的销项发票各类状态占比\n",
    "    out_ok = []  # 有效占比\n",
    "    out_fu = []  # 负数占比\n",
    "    out_not = []  # 作废占比\n",
    "    out_count = []  # 次数\n",
    "    out_money = []  # 金额\n",
    "    for i in id0:\n",
    "        # 获取总次数\n",
    "        df1_31 = df1_3[df1_3[\"企业代号\"]==i]\n",
    "        total = df1_31.count()[0]\n",
    "        ok_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]>=0)].count()[0] / total\n",
    "        fu_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]<0)].count()[0] / total\n",
    "        not_num = df1_31[df1_31[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "        money_avg = df1_31[df1_31[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "        out_ok.append(ok_num)\n",
    "        out_fu.append(fu_num)\n",
    "        out_not.append(not_num)\n",
    "        out_count.append(total)\n",
    "        out_money.append(money_avg)\n",
    "\n",
    "    df_new = pd.DataFrame({\"企业代号\": id0, \"进项有效发票占比\": in_ok, \"进项作废发票占比\": in_not, \"进项负数发票占比\": in_fu, \"进项次数\": in_count, \"进项平均每次金额\": in_money, \"销项有效发票占比\": out_ok, \"销项作废发票占比\": out_not, \"销项负数发票占比\": out_fu, \"销项次数\": out_count, \"销项平均每次金额\": out_money})\n",
    "    df_new.to_csv(f\"{name}.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "342a3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data(id0, \"整合数据1\")\n",
    "new_data(id1, \"整合数据2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414522ed",
   "metadata": {},
   "source": [
    "## 主成分分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0dbf1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mein(data):\n",
    "    data1 = np.array(data)\n",
    "    data_new = []\n",
    "    for i in data1:\n",
    "        data_new.append(list(np.delete(i, 0)))\n",
    "    data_new = np.array(data_new)\n",
    "\n",
    "    # 对每一个属性的样本求均值\n",
    "    MEAN = np.mean(data_new, axis=0)\n",
    "\n",
    "    # 去中心化\n",
    "    X = np.subtract(data_new, MEAN)\n",
    "\n",
    "    # 计算协方差矩阵\n",
    "    COV = np.dot(X.T, X)\n",
    "\n",
    "    # 计算特征值和特征向量\n",
    "    W, V = np.linalg.eig(COV)  # W特征值，V特征向量\n",
    "\n",
    "    # 计算主成分贡献率以及累计贡献率\n",
    "    sum_lambda = np.sum(W) # 特征值的和\n",
    "\n",
    "\n",
    "    f = np.divide(W, sum_lambda) # 每个特征值的贡献率（特征值 / 总和)\n",
    "    print(f)\n",
    "\n",
    "    # 前两大特征值对应的特征向量为：\n",
    "    e1 = V.T[0]\n",
    "    e2 = V.T[1]\n",
    "    print(e1)\n",
    "    print(e2)\n",
    "\n",
    "\n",
    "    # 计算主成分值（已去中心化）\n",
    "    z1 = np.dot(X, e1)\n",
    "    z2 = np.dot(X, e2)\n",
    "\n",
    "    # 输出降维后的结果（已去中心化）\n",
    "    RES = np.array([z1,z2])\n",
    "\n",
    "    return RES.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e79a16a",
   "metadata": {},
   "source": [
    "## 判别分析（距离）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1aec6f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.26372224e-01  2.73205910e-01  3.47266277e-04  7.45996069e-05\n",
      "  2.28850007e-13  2.81538237e-14  3.55141561e-14  2.19878489e-15\n",
      " -6.23444333e-19  4.05081714e-27]\n",
      "[-3.81976810e-08  3.08289423e-08  7.36873874e-09  1.35000222e-03\n",
      "  8.33231001e-01  4.16157259e-08 -3.65684690e-08 -5.04725691e-09\n",
      "  2.30658470e-03  5.52918580e-01]\n",
      "[ 1.68895929e-08 -1.76848444e-08  7.95251055e-10 -3.61856870e-03\n",
      "  5.52911247e-01  3.80390927e-08 -3.66473463e-08 -1.39174638e-09\n",
      "  3.40725299e-03 -8.33225329e-01]\n",
      "马氏距离分类结果:  ['C' 'A' 'A' 'B' 'B' 'A' 'A' 'A' 'C' 'A' 'C' 'A' 'C' 'A' 'A' 'A' 'A' 'B'\n",
      " 'B' 'A' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'C' 'A' 'A' 'B' 'B' 'A' 'B' 'B' 'C'\n",
      " 'C' 'A' 'A' 'C' 'A' 'C' 'C' 'A' 'C' 'C' 'B' 'D' 'C' 'B' 'C' 'A' 'B' 'A'\n",
      " 'C' 'C' 'A' 'A' 'D' 'B' 'A' 'A' 'B' 'B' 'B' 'B' 'D' 'B' 'C' 'B' 'B' 'C'\n",
      " 'D' 'A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'C' 'B' 'A' 'B' 'B' 'B' 'B' 'C'\n",
      " 'D' 'B' 'B' 'D' 'C' 'B' 'D' 'B' 'B' 'C' 'D' 'D' 'D' 'D' 'D' 'D' 'B']\n",
      "误差率: 0.3738317757009346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# 得到初始数据\n",
    "data = pd.read_csv(\"整合数据2.csv\")\n",
    "\n",
    "x0 = np.array(mein(data))\n",
    "\n",
    "# 处理马氏 44\n",
    "target = id1_degree\n",
    "\n",
    "v=np.cov(x0.T) #计算协方差\n",
    "\n",
    "knn = KNeighborsClassifier(4, metric='mahalanobis', metric_params={'V': v}) #马氏距离分类\n",
    "\n",
    "knn.fit(x0,target)\n",
    "\n",
    "pre=knn.predict(x0)\n",
    "print(\"马氏距离分类结果: \",pre)\n",
    "print(\"误差率:\", 1-knn.score(x0, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "d285bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.99119488e-01  9.32956944e-02  7.56020967e-03  2.46082156e-05\n",
      "  1.52900135e-11  1.16526031e-12  2.31244848e-13  2.64381165e-14\n",
      " -1.78395698e-19  2.17467264e-26]\n",
      "[ 5.43191500e-07 -4.93658024e-07 -4.95334756e-08 -1.20009672e-02\n",
      " -2.41228191e-01 -1.38794306e-06  1.39462755e-06 -6.68448920e-09\n",
      " -2.51852295e-03 -9.70390949e-01]\n",
      "[ 8.36330090e-09 -6.88792387e-09 -1.47537720e-09  7.14694840e-02\n",
      " -9.67989421e-01 -1.13188432e-06  6.59517348e-07  4.72366977e-07\n",
      "  2.08755717e-02  2.39693145e-01]\n",
      "欧氏距离分类结果:  ['C' 'C' 'B' 'C' 'C' 'C' 'C' 'C' 'C' 'D' 'C' 'D' 'D' 'D' 'D' 'D']\n",
      "误差率: 0.25\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"整合数据1.csv\")\n",
    "x01 = np.array(mein(data1))\n",
    "\n",
    "target1 = id0_degree\n",
    "\n",
    "v1=np.cov(x01.T) #计算协方差\n",
    "\n",
    "knn1 = KNeighborsClassifier(4) #欧氏距离分类\n",
    "\n",
    "knn1.fit(x01,target1)\n",
    "\n",
    "pre1=knn1.predict(x01)\n",
    "\n",
    "print(\"欧氏距离分类结果: \",pre1)\n",
    "\n",
    "print(\"误差率:\", 1-knn1.score(x01, target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "d8d3d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [[int(i[1:]), j] for i, j in zip(id0, pre1)] \n",
    "list2 = [[int(i[1:]), j] for i, j in zip(id1, pre)]\n",
    "list1.extend(list2)\n",
    "list1.sort()\n",
    "value = [i[1] for i in list1]\n",
    "df1_1.insert(3, column=\"判别归类\", value=value)\n",
    "df1_1.to_csv(\"原本评级和判别评级对比表.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc8652",
   "metadata": {},
   "source": [
    "## 第二问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6272ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1 = pd.read_excel(\"附件2：302家无信贷记录企业的相关数据.xlsx\", sheet_name=\"企业信息\")\n",
    "df2_2 = pd.read_excel(\"附件2：302家无信贷记录企业的相关数据.xlsx\", sheet_name=\"进项发票信息\")\n",
    "df2_3 = pd.read_excel(\"附件2：302家无信贷记录企业的相关数据.xlsx\", sheet_name=\"销项发票信息\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ce030367",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to = list(df2_1[\"企业代号\"])\n",
    "id0 = []\n",
    "id1 = []\n",
    "for i in id_to:\n",
    "    # 获取总次数\n",
    "    df1_31 = df2_3[df2_3[\"企业代号\"]==i]\n",
    "    total = df1_31.count()[0]\n",
    "    ok_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]>=0)].count()[0] / total\n",
    "    fu_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]<0)].count()[0] / total\n",
    "    not_num = df1_31[df1_31[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "    money_avg = df1_31[df1_31[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "    not_num1 = df1_31[(df1_31[\"发票状态\"]==\"作废发票\") & (df1_31[\"金额\"]==0)].count()[0] / total \n",
    "    if not_num1 > 0.05:\n",
    "        id0.append(i)\n",
    "    else:\n",
    "        id1.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "05c789f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取企业代号\n",
    "def new_data(id0, name):\n",
    "    # 每个企业对应的进项发票各类状态占比\n",
    "    in_ok = []  # 有效占比\n",
    "    in_fu = []  # 负数占比\n",
    "    in_not = []  # 作废占比\n",
    "    in_count = []  # 次数\n",
    "    in_money = []  # 金额/次\n",
    "    for i in id0:\n",
    "        # 获取总次数\n",
    "        df1_21 = df2_2[df2_2[\"企业代号\"]==i]\n",
    "        total = df1_21.count()[0]\n",
    "        ok_num = df1_21[(df1_21[\"发票状态\"]==\"有效发票\") & (df1_21[\"金额\"]>=0)].count()[0] / total\n",
    "        fu_num = df1_21[(df1_21[\"发票状态\"]==\"有效发票\") & (df1_21[\"金额\"]<0)].count()[0] / total\n",
    "        not_num = df1_21[df1_21[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "        money_avg = df1_21[df1_21[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "        in_ok.append(ok_num)\n",
    "        in_fu.append(fu_num)\n",
    "        in_not.append(not_num)\n",
    "        in_count.append(total)\n",
    "        in_money.append(money_avg)\n",
    "\n",
    "    # 每个企业对应的销项发票各类状态占比\n",
    "    out_ok = []  # 有效占比\n",
    "    out_fu = []  # 负数占比\n",
    "    out_not = []  # 作废占比\n",
    "    out_count = []  # 次数\n",
    "    out_money = []  # 金额\n",
    "    for i in id0:\n",
    "        # 获取总次数\n",
    "        df1_31 = df2_3[df2_3[\"企业代号\"]==i]\n",
    "        total = df1_31.count()[0]\n",
    "        ok_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]>=0)].count()[0] / total\n",
    "        fu_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]<0)].count()[0] / total\n",
    "        not_num = df1_31[df1_31[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "        money_avg = df1_31[df1_31[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "        out_ok.append(ok_num)\n",
    "        out_fu.append(fu_num)\n",
    "        out_not.append(not_num)\n",
    "        out_count.append(total)\n",
    "        out_money.append(money_avg)\n",
    "\n",
    "    df_new = pd.DataFrame({\"企业代号\": id0, \"进项有效发票占比\": in_ok, \"进项作废发票占比\": in_not, \"进项负数发票占比\": in_fu, \"进项次数\": in_count, \"进项平均每次金额\": in_money, \"销项有效发票占比\": out_ok, \"销项作废发票占比\": out_not, \"销项负数发票占比\": out_fu, \"销项次数\": out_count, \"销项平均每次金额\": out_money})\n",
    "    df_new.to_csv(f\"{name}.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "bd909eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data(id0, \"整合数据3\") # 这个是二类  knn1\n",
    "new_data(id1, \"整合数据4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "47104e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欧氏距离分类结果:  ['B' 'C' 'C' 'C' 'C' 'D' 'C' 'C' 'C' 'D' 'C' 'D' 'C' 'D' 'D' 'C' 'C' 'D'\n",
      " 'D' 'D']\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"整合数据3.csv\")\n",
    "x01 = np.array(mein(data1))\n",
    "\n",
    "pre1=knn1.predict(x01)\n",
    "\n",
    "print(\"欧氏距离分类结果: \",pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "62b25f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欧氏距离分类结果:  ['B' 'B' 'A' 'B' 'B' 'C' 'A' 'A' 'B' 'B' 'C' 'B' 'C' 'B' 'B' 'C' 'B' 'C'\n",
      " 'C' 'A' 'B' 'C' 'A' 'A' 'B' 'B' 'B' 'B' 'A' 'B' 'A' 'C' 'B' 'A' 'B' 'B'\n",
      " 'A' 'B' 'B' 'B' 'A' 'C' 'A' 'C' 'B' 'A' 'A' 'C' 'C' 'C' 'A' 'C' 'B' 'B'\n",
      " 'A' 'A' 'A' 'C' 'C' 'B' 'A' 'C' 'A' 'B' 'C' 'A' 'B' 'A' 'A' 'C' 'D' 'C'\n",
      " 'C' 'A' 'B' 'A' 'A' 'C' 'A' 'A' 'A' 'C' 'A' 'A' 'C' 'B' 'B' 'A' 'B' 'C'\n",
      " 'B' 'B' 'A' 'A' 'A' 'C' 'A' 'A' 'C' 'C' 'B' 'A' 'A' 'B' 'B' 'B' 'B' 'B'\n",
      " 'A' 'A' 'A' 'C' 'C' 'B' 'C' 'A' 'A' 'A' 'B' 'A' 'B' 'C' 'A' 'C' 'B' 'A'\n",
      " 'A' 'A' 'C' 'C' 'B' 'A' 'C' 'C' 'A' 'C' 'B' 'C' 'B' 'B' 'C' 'B' 'B' 'A'\n",
      " 'A' 'C' 'B' 'B' 'B' 'B' 'C' 'C' 'C' 'B' 'A' 'B' 'C' 'B' 'C' 'C' 'C' 'C'\n",
      " 'B' 'A' 'B' 'A' 'C' 'C' 'A' 'B' 'A' 'C' 'B' 'A' 'C' 'A' 'C' 'B' 'C' 'C'\n",
      " 'B' 'C' 'A' 'A' 'B' 'C' 'A' 'C' 'A' 'A' 'A' 'A' 'B' 'A' 'B' 'B' 'D' 'A'\n",
      " 'A' 'B' 'C' 'B' 'C' 'B' 'C' 'B' 'C' 'A' 'D' 'A' 'B' 'C' 'D' 'B' 'C' 'A'\n",
      " 'C' 'B' 'C' 'A' 'C' 'C' 'D' 'D' 'B' 'B' 'B' 'D' 'A' 'A' 'A' 'C' 'D' 'B'\n",
      " 'D' 'C' 'C' 'D' 'C' 'C' 'D' 'D' 'A' 'D' 'C' 'A' 'B' 'B' 'D' 'D' 'D' 'B'\n",
      " 'D' 'D' 'C' 'C' 'D' 'B' 'C' 'A' 'B' 'C' 'A' 'B' 'B' 'D' 'D' 'D' 'D' 'D'\n",
      " 'B' 'C' 'C' 'A' 'B' 'C' 'C' 'D' 'D' 'C' 'C' 'D']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"整合数据4.csv\")\n",
    "x1 = np.array(mein(data))\n",
    "\n",
    "pre=knn.predict(x1)\n",
    "\n",
    "print(\"欧氏距离分类结果: \",pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "968b7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [[int(i[1:]), j] for i, j in zip(id0, pre1)] \n",
    "list2 = [[int(i[1:]), j] for i, j in zip(id1, pre)]\n",
    "list1.extend(list2)\n",
    "list1.sort()\n",
    "value = [i[1] for i in list1]\n",
    "df2_1.insert(2, column=\"判别归类\", value=value)\n",
    "df2_1.to_csv(\"判别评级表.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "381a3928",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[17:31:21] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (109 vs. 0) : Incorrect size for labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[244], line 36\u001b[0m\n\u001b[0;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooster\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnthread\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     34\u001b[0m }\n\u001b[0;32m     35\u001b[0m plst \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m---> 36\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 生成数据集格式\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(params,\n\u001b[0;32m     38\u001b[0m                   dtrain,  \u001b[38;5;66;03m# 训练的数据\u001b[39;00m\n\u001b[0;32m     39\u001b[0m                   num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m  \u001b[38;5;66;03m# 提升迭代的个数\u001b[39;00m\n\u001b[0;32m     40\u001b[0m                   ) \u001b[38;5;66;03m# xgboost模型训练\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 对测试集进行预测\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\core.py:754\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n\u001b[1;32m--> 754\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m=\u001b[39m feature_names\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\core.py:819\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[1;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 819\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_weight(weight)\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\core.py:950\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;124;03m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m--> 950\u001b[0m \u001b[43mdispatch_meta_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\data.py:1121\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[1;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data):\n\u001b[1;32m-> 1121\u001b[0m     \u001b[43m_meta_from_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_tuple(data):\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\data.py:1060\u001b[0m, in \u001b[0;36m_meta_from_list\u001b[1;34m(data, field, dtype, handle)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta_from_list\u001b[39m(\n\u001b[0;32m   1054\u001b[0m     data: Sequence,\n\u001b[0;32m   1055\u001b[0m     field: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1056\u001b[0m     dtype: Optional[NumpyDType],\n\u001b[0;32m   1057\u001b[0m     handle: ctypes\u001b[38;5;241m.\u001b[39mc_void_p\n\u001b[0;32m   1058\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     data_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n\u001b[1;32m-> 1060\u001b[0m     \u001b[43m_meta_from_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\data.py:1050\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[1;34m(data, field, dtype, handle)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasked array is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1049\u001b[0m interface_str \u001b[38;5;241m=\u001b[39m _array_interface(data)\n\u001b[1;32m-> 1050\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixSetInfoFromInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Bin\\envir\\python\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [17:31:21] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (109 vs. 0) : Incorrect size for labels."
     ]
    }
   ],
   "source": [
    "# 基于XGBoost原生接口的分类\n",
    "from sklearn.datasets import load_iris\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score   # 准确率\n",
    "\n",
    "mo = []\n",
    "for i in target:\n",
    "    if i == \"A\":\n",
    "        mo.append(1)\n",
    "    elif i == \"B\":\n",
    "        mo.append(2)\n",
    "    elif i == \"C\":\n",
    "        mo.append(3)\n",
    "    elif i == \"D\":\n",
    "        mo.append(4)\n",
    "\n",
    "x_data, y_data = data_new, mo\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'eta': 0.1,\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,\n",
    "}\n",
    "plst = params.items()\n",
    "dtrain = xgb.DMatrix(x_data, y_data)  # 生成数据集格式\n",
    "model = xgb.train(params,\n",
    "                  dtrain,  # 训练的数据\n",
    "                  num_boost_round=500  # 提升迭代的个数\n",
    "                  ) # xgboost模型训练\n",
    " \n",
    " \n",
    "# 对测试集进行预测\n",
    "dtest = xgb.DMatrix(x_data)\n",
    "y_pred = model.predict(dtest)\n",
    "print(y_pred)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_data,y_pred)\n",
    "print(\"accuarcy: %.2f%%\" % (accuracy*100.0))\n",
    " \n",
    "# 显示重要特征\n",
    "# plot_importance(model)\n",
    "# plt.show()\n",
    "\n",
    " \n",
    "# # ================基于XGBoost原生接口的回归=============\n",
    " \n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.datasets import load_boston\n",
    "# from sklearn.metrics import mean_squared_error\n",
    " \n",
    "# # 加载数据集\n",
    "# boston = load_boston()\n",
    "# X,y = boston.data,boston.target\n",
    " \n",
    "# # XGBoost训练过程\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    " \n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'reg:gamma',\n",
    "#     'gamma': 0.1,\n",
    "#     'max_depth': 5,\n",
    "#     'lambda': 3,\n",
    "#     'subsample': 0.7,\n",
    "#     'colsample_bytree': 0.7,\n",
    "#     'min_child_weight': 3,\n",
    "#     'silent': 1,\n",
    "#     'eta': 0.1,\n",
    "#     'seed': 1000,\n",
    "#     'nthread': 4,\n",
    "# }\n",
    " \n",
    "# dtrain = xgb.DMatrix(X_train, y_train)\n",
    "# model = xgb.train(params, dtrain, num_boost_round=500)\n",
    " \n",
    "# # 对测试集进行预测\n",
    "# dtest = xgb.DMatrix(X_test)\n",
    "# ans = model.predict(dtest)\n",
    " \n",
    "# # 显示重要特征\n",
    "# plot_importance(model)\n",
    "# plt.show()\n",
    " \n",
    " \n",
    " \n",
    "# # ==============基于Scikit-learn接口的分类================\n",
    "# from sklearn.datasets import load_iris\n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    " \n",
    "# # 加载样本数据集\n",
    "# iris = load_iris()\n",
    "# X,y = iris.data,iris.target\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234565) # 数据集分割\n",
    " \n",
    "# # 训练模型\n",
    "# model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=160, silent=True, objective='multi:softmax')\n",
    "# model.fit(X_train, y_train)\n",
    " \n",
    "# # 对测试集进行预测\n",
    "# y_pred = model.predict(X_test)\n",
    " \n",
    "# # 计算准确率\n",
    "# accuracy = accuracy_score(y_test,y_pred)\n",
    "# print(\"accuarcy: %.2f%%\" % (accuracy*100.0))\n",
    " \n",
    "# # 显示重要特征\n",
    "# plot_importance(model)\n",
    "# plt.show()\n",
    " \n",
    " \n",
    "# # ================基于Scikit-learn接口的回归================\n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.datasets import load_boston\n",
    " \n",
    "# boston = load_boston()\n",
    "# X,y = boston.data,boston.target\n",
    " \n",
    "# # XGBoost训练过程\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    " \n",
    "# model = xgb.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=160, silent=True, objective='reg:gamma')\n",
    "# model.fit(X_train, y_train)\n",
    " \n",
    "# # 对测试集进行预测\n",
    "# ans = model.predict(X_test)\n",
    " \n",
    "# # 显示重要特征\n",
    "# plot_importance(model)\n",
    "# plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d9ff5fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E13', 'E32', 'E34', 'E40', 'E52', 'E53', 'E55', 'E72', 'E90', 'E102', 'E107', 'E111', 'E119', 'E120', 'E121', 'E123']\n"
     ]
    }
   ],
   "source": [
    "id_to = list(df1_1[\"企业代号\"])\n",
    "id = []\n",
    "id1 = []\n",
    "for i in id_to:\n",
    "    # 获取总次数\n",
    "    df1_31 = df1_3[df1_3[\"企业代号\"]==i]\n",
    "    total = df1_31.count()[0]\n",
    "    ok_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]>=0)].count()[0] / total\n",
    "    fu_num = df1_31[(df1_31[\"发票状态\"]==\"有效发票\") & (df1_31[\"金额\"]<0)].count()[0] / total\n",
    "    not_num = df1_31[df1_31[\"发票状态\"]==\"作废发票\"].count()[0] / total\n",
    "    money_avg = df1_31[df1_31[\"金额\"]>=0][\"金额\"].sum() / total\n",
    "    not_num1 = df1_31[(df1_31[\"发票状态\"]==\"作废发票\") & (df1_31[\"金额\"]==0)].count()[0] / total \n",
    "    if not_num1 > 0.05:\n",
    "        id.append(i)\n",
    "    else:\n",
    "        id1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce42394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
